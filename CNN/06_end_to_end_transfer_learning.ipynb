{"cells":[{"cell_type":"markdown","metadata":{"id":"i9a-ACKHKLk5"},"source":["# Fine Tuning with MobileNetV2 Backbone"]},{"cell_type":"markdown","metadata":{"id":"cikYTNBnwjvY"},"source":["# Imports\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"UTyoCE5Uo1i6"},"outputs":[],"source":["# !pip uninstall tf-keras\n","# !pip install tensorflow==2.16.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvaL7HEeo2l-"},"outputs":[],"source":["import keras\n","import tensorflow as tf\n","print(\"Keras Current Version:\", keras.__version__, \"Tensorflow Current Version:\", tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tPOV_sAguwzf"},"outputs":[],"source":["import os, random, datetime\n","from glob import glob\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.metrics import Accuracy, AUC\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models  import load_model\n","\n","# Tensorflow ve Keras kütüphaneleri\n","import tensorflow as tf\n","from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input as preprocess_input_mobilenetv2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, Flatten, MaxPooling2D, Dropout, SpatialDropout2D\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"]},{"cell_type":"markdown","metadata":{"id":"ewsR2xmYLNGP"},"source":["# Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_tqJ_Kb04pz"},"outputs":[],"source":["def get_image_paths(root_dir, num_images=None):\n","    all_images = []\n","    for extension in ['*.jpg', '*.jpeg', '*.png']:\n","        all_images.extend(glob(os.path.join(root_dir, '**', extension), recursive=True))\n","    if num_images is None:\n","        return all_images\n","    else:\n","        return random.sample(all_images, min(num_images, len(all_images)))\n","\n","def display_images(img_list):\n","    plt.figure(figsize=(15, 6))\n","    for i, img_path in enumerate(img_list):\n","        img = image.load_img(img_path)\n","        img = image.img_to_array(img, dtype=np.uint8)\n","        plt.subplot(2, 5, i + 1)\n","        plt.imshow(img.squeeze())\n","        plt.axis('off')\n","        plt.title(f'Image {i+1}')\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def print_predicted_classes(predicted_classes):\n","    for full_path, (label, probability) in predicted_classes.items():\n","        filename = os.path.basename(full_path)\n","        print(f\"{filename}: {label} ({probability:.2f}%)\")\n","\n","def plot_training_history(history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy'):\n","\n","    #Loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(history.history[train_loss], label='Training Loss')\n","    plt.plot(history.history[val_loss], label='Validation Loss')\n","    plt.title('Training and Validation Loss Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Metrics\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(history.history[train_metric], label=f\"Training: {train_metric}\")\n","    plt.plot(history.history[val_metric], label=f\"Validation: {val_metric}\")\n","    plt.title(f'Training and Validation {train_metric} Over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel(f'train_metric')\n","    plt.legend()\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"ZQ9Ewt9Ev3Y6"},"source":["# Data Preparation & Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3GIoTEvbCkE"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFNOihU_u-Qf"},"outputs":[],"source":["dir_path = '/content/drive/MyDrive/Colab Notebooks/Garbage classification'"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"qvxPKHIhu_mR"},"outputs":[],"source":["img_list = get_image_paths(dir_path)\n","\n","len(img_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Li9Cwab0HF0W"},"outputs":[],"source":["# 501 glass\n","# 594 paper\n","# 403 cardboard\n","# 482 plastic\n","# 410 metal\n","# 137 trash"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"pww6irWEwaJm"},"outputs":[],"source":["display_images(img_list[0:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSSB64jidMav"},"outputs":[],"source":["train = ImageDataGenerator(horizontal_flip=True,\n","                         vertical_flip=True,\n","                         validation_split=0.1,\n","                         rescale=1./255,\n","                         shear_range = 0.1,\n","                         zoom_range = 0.1,\n","                         width_shift_range = 0.1,\n","                         height_shift_range = 0.1,)\n","\n","\n","val = ImageDataGenerator(rescale=1/255,\n","                        validation_split=0.1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Vzwn7jYXevu8"},"outputs":[],"source":["train_generator=train.flow_from_directory(dir_path,\n","                                          target_size=(224, 224),\n","                                          batch_size=32,\n","                                          class_mode='categorical',\n","                                          subset='training')\n","\n","validation_generator=val.flow_from_directory(dir_path,\n","                                        target_size=(224, 224),\n","                                        batch_size=251,\n","                                        class_mode='categorical',\n","                                        subset='validation')\n"]},{"cell_type":"markdown","metadata":{"id":"0mePppcZKKyg"},"source":["# Frozen Layers\n"]},{"cell_type":"markdown","metadata":{"id":"SL-Y6s8i1nbd"},"source":["## MobilenetV2 Backbone"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jp2QMgEx2X6P"},"outputs":[],"source":["mobilenet_backbone = MobileNetV2(weights='imagenet',\n","\n","                                 include_top=False,\n","\n","                                 input_shape=(224, 224, 3))\n","\n","#alpha=1.0\n","#classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wN_YnQN99VVU"},"outputs":[],"source":["mobilenet_backbone.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIECFPxT1NJ0"},"outputs":[],"source":["print(f\"Total number of layers in MobileNetV2: {len(mobilenet_backbone.layers)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ns3pt8E82YuN"},"outputs":[],"source":["block_count = 0\n","for layer in mobilenet_backbone.layers:\n","    if isinstance(layer, tf.keras.layers.Conv2D) and 'expand' in layer.name:\n","        block_count += 1\n","\n","print(f\"Number of logical 'blocks' in MobileNetV2: {block_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nupzTJy43gW6"},"outputs":[],"source":["for layer in mobilenet_backbone.layers:\n","    print(layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZwX7qu93_h3"},"outputs":[],"source":["for layer in mobilenet_backbone.layers[-11:]:\n","    print(layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlTPNa4Q8N3a"},"outputs":[],"source":["for layer in mobilenet_backbone.layers:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"tJ0BDObP47r3"},"outputs":[],"source":["for layer in mobilenet_backbone.layers:\n","    print(layer.name, layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"C4i-Fkyf1_GM"},"outputs":[],"source":["for layer in mobilenet_backbone.layers[-11:]:\n","    layer.trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yE36fioz5OjN"},"outputs":[],"source":["for layer in mobilenet_backbone.layers:\n","    print(layer.name, layer.trainable)"]},{"cell_type":"markdown","metadata":{"id":"yaZkEeNPBggK"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHLxrjHT4dSr"},"outputs":[],"source":["x = GlobalAveragePooling2D()(mobilenet_backbone.output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJEMY07HAYv1"},"outputs":[],"source":["x = Dense(6, activation='softmax')(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QZ5KHdUAwwx"},"outputs":[],"source":["fine_tuning_model = Model(inputs=mobilenet_backbone.input, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsYhkmx38vsK"},"outputs":[],"source":["metrics = [\"accuracy\", AUC(name='auc', multi_label=True)]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2atFZQE-A0jo"},"outputs":[],"source":["from tensorflow.keras.optimizers import SGD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9GemflP5r6k"},"outputs":[],"source":["optimizer=SGD(learning_rate=0.0001, momentum=0.9, nesterov=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W686uWS0AVpH"},"outputs":[],"source":["fine_tuning_model.compile(optimizer=optimizer,\n","              loss='categorical_crossentropy',\n","              metrics=metrics)\n","\n","early_stopping = EarlyStopping(monitor='val_loss',\n","                               patience=10,\n","                               restore_best_weights=True,\n","                               verbose=1)\n","\n","\n","model_checkpoint = ModelCheckpoint('mobilenetv2_finetuned.keras',\n","                                   monitor='val_loss',\n","                                   save_best_only=True,\n","                                   save_weights_only=False,\n","                                   verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3znEqu2vCCUK"},"outputs":[],"source":["start_time = datetime.datetime.now()\n","\n","fine_tuning_model_history = fine_tuning_model.fit(\n","    train_generator,\n","    epochs=100,\n","    validation_data=validation_generator,\n","    callbacks=[early_stopping, model_checkpoint]\n",")\n","\n","end_time = datetime.datetime.now()\n","\n","total_duration = end_time - start_time\n","print(\"Training Time:\", total_duration)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2UxSZfl5199"},"outputs":[],"source":["plot_training_history(fine_tuning_model_history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpJ1sNS-F9El"},"outputs":[],"source":["plot_training_history(fine_tuning_model_history, train_loss='loss', train_metric='auc', val_loss='val_loss', val_metric='val_auc')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QauRwxzF9Gs"},"outputs":[],"source":["val_loss, val_accuracy, val_auc = fine_tuning_model.evaluate(validation_generator, verbose=0)\n","print(f\"Loss: {val_loss}\")\n","print(f\"Accuracy: {val_accuracy}\")\n","print(f\"AUC: {val_auc}\")"]},{"cell_type":"markdown","metadata":{"id":"8MX51093KKyi"},"source":["## Prediction & Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9Ro-oevP5W5"},"outputs":[],"source":["waste_labels = {0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7a3BAbSxHIzP"},"outputs":[],"source":["dir_path = '/content/drive/MyDrive/Colab Notebooks/Garbage classification'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOM8mmGHHI1Z"},"outputs":[],"source":["img_list = get_image_paths(dir_path, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NS56jtlQJrqK"},"outputs":[],"source":["garbage_tuned_model = load_model('/content/mobilenetv2_finetuned.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpIn_hfsGFpS"},"outputs":[],"source":["def preprocess_mobilenet(img_path):\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = preprocess_input_mobilenetv2(img_array)\n","    return img_array\n","\n","def predict_mobilenet(model, img_array, class_labels):\n","    predictions = model.predict(img_array, verbose=0)\n","    predicted_class_idx = np.argmax(predictions[0])\n","    predicted_class = class_labels[predicted_class_idx]\n","    probability = np.max(predictions[0])\n","    return predicted_class, probability\n","\n","def visualise_preds_mobilenet(model, image_paths, class_labels, visualize=False):\n","    results = {}\n","    for img_path in image_paths:\n","        img_array = preprocess_mobilenet(img_path)\n","        label, probability = predict_mobilenet(model, img_array, class_labels)\n","        results[img_path] = (label, probability)\n","        if visualize:\n","            plt.figure(figsize=(5, 5))\n","            plt.imshow(image.load_img(img_path))\n","            plt.title(f\"Predicted: {label} ({probability:.2f}%)\")\n","            plt.axis('off')\n","            plt.show()\n","\n","    return results\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5PIdsbQPK-6"},"outputs":[],"source":["predicted_classes = visualise_preds_mobilenet(garbage_tuned_model, img_list, waste_labels, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWHanpflFCEY"},"outputs":[],"source":["print_predicted_classes(predicted_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_DdHkhbFCGe"},"outputs":[],"source":["img_list2 = get_image_paths(dir_path, 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ga_jdGnGFCIX"},"outputs":[],"source":["predicted_classes2 = visualise_preds_mobilenet(garbage_tuned_model, img_list2, waste_labels, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUQC3Z1GFCKO"},"outputs":[],"source":["print_predicted_classes(predicted_classes2)"]},{"cell_type":"markdown","metadata":{"id":"xLbJRAppl-uw"},"source":["# Full Network Fine Tuning\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation & Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRc0Dj70Vtbq"},"outputs":[],"source":["dir_path = '/content/drive/MyDrive/Colab Notebooks/Garbage classification'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0SGMnFRVwwM"},"outputs":[],"source":["img_list = get_image_paths(dir_path)\n","\n","len(img_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_Alw5ipVhrV"},"outputs":[],"source":["train = ImageDataGenerator(horizontal_flip=True,\n","                         vertical_flip=True,\n","                         validation_split=0.1,\n","                         rescale=1./255,\n","                         shear_range = 0.1,\n","                         zoom_range = 0.1,\n","                         width_shift_range = 0.1,\n","                         height_shift_range = 0.1,)\n","\n","\n","val = ImageDataGenerator(rescale=1/255,\n","                        validation_split=0.1)\n","\n","train_generator=train.flow_from_directory(dir_path,\n","                                          target_size=(224, 224),\n","                                          batch_size=32,\n","                                          class_mode='categorical',\n","                                          subset='training')\n","\n","validation_generator=val.flow_from_directory(dir_path,\n","                                        target_size=(224, 224),\n","                                        batch_size=251,\n","                                        class_mode='categorical',\n","                                        subset='validation')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcDdedVpVeEY"},"outputs":[],"source":["mobilenet_backbone_full = MobileNetV2(weights='imagenet',\n","                                 include_top=False,\n","                                 input_shape=(224, 224, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3KJIeEVLq79"},"outputs":[],"source":["for layer in mobilenet_backbone_full.layers:\n","    layer.trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgrVxZEeq5SZ"},"outputs":[],"source":["x = GlobalAveragePooling2D()(mobilenet_backbone_full.output)\n","\n","x = Dense(6, activation='softmax')(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWAvU091q5Ud"},"outputs":[],"source":["full_network_fine_tuning = Model(inputs=mobilenet_backbone_full.input, outputs=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXXi9wHsq5Wx"},"outputs":[],"source":["metrics = [\"accuracy\", AUC(name='auc', multi_label=True)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vy1tTCgcq5ZK"},"outputs":[],"source":["from tensorflow.keras.optimizers import SGD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDfOKcD4q5bH"},"outputs":[],"source":["optimizer=SGD(learning_rate=0.0001, momentum=0.9, nesterov=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9iD0MZhGsr1i"},"outputs":[],"source":["full_network_fine_tuning.compile(optimizer,\n","              loss='categorical_crossentropy',\n","              metrics=metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhvKaYxBq5dT"},"outputs":[],"source":["early_stopping_full = EarlyStopping(monitor='val_loss',\n","                               patience=10,\n","                               restore_best_weights=True,\n","                               verbose=1)\n","\n","\n","model_checkpoint_full = ModelCheckpoint('mobilenetv2_full_network.keras',\n","                                   monitor='val_loss',\n","                                   save_best_only=True,\n","                                   save_weights_only=False,\n","                                   verbose=1)\n"]},{"cell_type":"markdown","metadata":{"id":"G3M4_4lltlHs"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRTw_dbjLPY4"},"outputs":[],"source":["start_time = datetime.datetime.now()\n","\n","full_network_history = full_network_fine_tuning.fit(\n","    train_generator,\n","    epochs=30,\n","    validation_data=validation_generator,\n","    callbacks=[early_stopping_full, model_checkpoint_full]\n",")\n","\n","end_time = datetime.datetime.now()\n","\n","total_duration = end_time - start_time\n","print(\"Training Time:\", total_duration)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqYDaxgyLPbI"},"outputs":[],"source":["plot_training_history(full_network_history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRZcmX_Otz1W"},"outputs":[],"source":["plot_training_history(full_network_history, train_loss='loss', train_metric='auc', val_loss='val_loss', val_metric='val_auc')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFBhpI_QusS4"},"outputs":[],"source":["val_loss, val_accuracy, val_auc = full_network_fine_tuning.evaluate(validation_generator, verbose=0)\n","print(f\"Loss: {val_loss}\")\n","print(f\"Accuracy: {val_accuracy}\")\n","print(f\"AUC: {val_auc}\")"]},{"cell_type":"markdown","metadata":{"id":"9rR8OVu2MOPE"},"source":["## Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LadtZ6MBPTEi"},"outputs":[],"source":["waste_labels = {0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ost3ZxcqMOPE"},"outputs":[],"source":["dir_path = '/content/drive/MyDrive/Colab Notebooks/Garbage classification'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c6weAfcMOPE"},"outputs":[],"source":["img_list = get_image_paths(dir_path, 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kgxd9eJMOPE"},"outputs":[],"source":["garbage_full_tuned_model = load_model('mobilenetv2_full_network.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbU16aQhMOPE"},"outputs":[],"source":["def preprocess_mobilenet(img_path):\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = preprocess_input_mobilenetv2(img_array)\n","    return img_array\n","\n","def predict_mobilenet(model, img_array, class_labels):\n","    predictions = model.predict(img_array, verbose=0)\n","    predicted_class_idx = np.argmax(predictions[0])\n","    predicted_class = class_labels[predicted_class_idx]\n","    probability = np.max(predictions[0])\n","    return predicted_class, probability\n","\n","def visualise_preds_mobilenet(model, image_paths, class_labels, visualize=False):\n","    results = {}\n","    for img_path in image_paths:\n","        img_array = preprocess_mobilenet(img_path)\n","        label, probability = predict_mobilenet(model, img_array, class_labels)\n","        results[img_path] = (label, probability)\n","        if visualize:\n","            plt.figure(figsize=(5, 5))\n","            plt.imshow(image.load_img(img_path))\n","            plt.title(f\"Predicted: {label} ({probability:.2f}%)\")\n","            plt.axis('off')\n","            plt.show()\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9du2aiVSKq3"},"outputs":[],"source":["predicted_classes = visualise_preds_mobilenet(garbage_full_tuned_model, img_list, waste_labels, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eD6aCSD-MOPE"},"outputs":[],"source":["print_predicted_classes(predicted_classes)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1lSekB2X3CkCJvhEn6dGFiG6-sSJ6hSgX","timestamp":1715675168027}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
